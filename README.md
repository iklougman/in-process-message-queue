# in-process-message-queue

ğŸ§µ A lightweight, in-process async job queue with per-key isolation, retries, and rate-limiting â€” perfect for bots, messaging systems, or any task throttling.

[![npm version](https://img.shields.io/npm/v/in-process-message-queue.svg)](https://www.npmjs.com/package/in-process-message-queue)
[![GitHub](https://img.shields.io/github/license/iklougman/in-process-message-queue)](https://github.com/iklougman/in-process-message-queue)

---

## ğŸš€ Features

* ğŸ§¹ **Per-Key Isolation** â€“ Tasks with the same key are processed sequentially, but different keys run concurrently.
* ğŸ–ï¸ **Automatic Retries** â€“ Define retry logic to gracefully handle failures.
* â±ï¸ **Rate Limiting** â€“ Limit how frequently tasks for a specific key or globally are processed.
* ï¿½ï¿½ **Lightweight** â€“ No external dependencies.
* ğŸ§  **Deterministic Execution** â€“ Avoid race conditions and concurrency bugs common in bot/messaging systems.

---

## ğŸ“† Install

```bash
npm install in-process-message-queue
```

---

## âœï¸ Usage

```ts
import { MultiQueueManager } from "in-process-message-queue";

const queue = new MultiQueueManager();

queue.add("chat123", async () => {
  await sendMessageToUser();
});
```

You can submit multiple tasks for different keys:

```ts
queue.add("chat123", async () => {
  await sendMessageToUser("User A");
});

queue.add("chat456", async () => {
  await sendMessageToUser("User B");
});
```

In this case:

* Messages to `chat123` are handled **in order**.
* Messages to `chat456` run **in parallel** with `chat123`.

---

## ğŸŒš Why Not Just `Promise.all`?

While `Promise.all` runs tasks in parallel, it **lacks control** over:

| Feature              | `Promise.all`    | `in-process-message-queue` |
| -------------------- | ---------------- | -------------------------- |
| Parallel execution   | âœ… Yes            | âœ… Yes                      |
| Ordered execution    | âŒ No (unordered) | âœ… Per-key FIFO             |
| Rate limiting        | âŒ No             | âœ… Built-in                 |
| Per-key queuing      | âŒ No             | âœ… Yes                      |
| Retry mechanism      | âŒ No             | âœ… Optional per task        |
| Fine-grained control | âŒ No             | âœ… Designed for control     |

In real-world applications like bots, chat systems, and task pipelines, **uncontrolled concurrency** leads to:

* Race conditions
* API rate limit violations
* Poor user experience

`in-process-message-queue` offers structure, safety, and consistency for async-heavy codebases.

---

## ğŸ“œ Example: Throttled Bot Messaging

```ts
queue.add("user42", async () => {
  await sendTypingIndicator();
  await wait(2000);
  await sendMessage("Hello there!");
});
```

Every user's message queue runs in isolation â€” like having a personal conveyor belt.

---

## ğŸ”§ Advanced Options (Coming Soon)

* Max retries with backoff
* Global concurrency limits
* Task cancellation
* Idle detection and cleanup

---

## ğŸ“‚ Project Structure

* `MultiQueueManager` â€“ the main interface to schedule isolated task queues.
* `InProcessQueue` â€“ internal class managing single-key job execution.
* Zero dependencies for full portability.

---

## ğŸ› ï¸ Contributing

Issues and PRs are welcome! See the [issues](https://github.com/iklougman/in-process-message-queue/issues) tab or suggest features that help async orchestration.

---

## ğŸ“„ License

MIT Â© [iklougman](https://github.com/iklougman)
